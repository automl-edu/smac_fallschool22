{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "py38",
      "display_name": "Python 3.8"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SMAC: Sequential Model Algorithm Configuration\n",
        "\n",
        "This notebook shows how to use SMAC (v2.0.0a1) to optimize hyperparameters.\n",
        "We refer to the [documentation](https://automl.github.io/SMAC3/development-2.0/) for more examples and details.\n",
        "\n",
        "Note: After executing the first block, you need to reload your browser!"
      ],
      "metadata": {
        "id": "DhomzHpx4d5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4lm29EatZh0"
      },
      "outputs": [],
      "source": [
        "# We basically install a new ipykernel\n",
        "!wget -O mini.sh https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.2-Linux-x86_64.sh\n",
        "!chmod +x mini.sh\n",
        "!bash ./mini.sh -b -f -p /usr/local\n",
        "!conda install -q -y jupyter\n",
        "!conda install -q -y google-colab -c conda-forge\n",
        "!python -m ipykernel install --name \"py38\" --user\n",
        "\n",
        "print(\"\\nPlease reload the browser to activate Python 3.8.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if we have the right python version\n",
        "import sys\n",
        "assert sys.version_info.major == 3\n",
        "assert sys.version_info.minor == 8\n",
        "\n",
        "# Now we install SMAC\n",
        "!apt-get install swig\n",
        "!pip install matplotlib\n",
        "!pip install git+https://github.com/automl/SMAC3.git@development-2.0#egg=smac\n",
        "# !pip install smac==2.0.0a1"
      ],
      "metadata": {
        "id": "HD01WW-mLxTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d985f1-6950-4860-fc78-a0f85a97e2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "swig is already the newest version (3.0.12-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/site-packages (3.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (9.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/site-packages (from matplotlib) (4.37.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/site-packages (from matplotlib) (1.23.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: smac from git+https://github.com/automl/SMAC3.git@development-2.0#egg=smac in /usr/local/lib/python3.8/site-packages (2.0.0a1)\n",
            "Requirement already satisfied: emcee>=3.0.0 in /usr/local/lib/python3.8/site-packages (from smac) (3.1.3)\n",
            "Requirement already satisfied: pyrfr>=0.8.3 in /usr/local/lib/python3.8/site-packages (from smac) (0.8.3)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.8/site-packages (from smac) (1.23.3)\n",
            "Requirement already satisfied: ConfigSpace>=0.6.0 in /usr/local/lib/python3.8/site-packages (from smac) (0.6.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/site-packages (from smac) (2022.9.13)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/site-packages (from smac) (6.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.8/site-packages (from smac) (1.9.2)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.8/site-packages (from smac) (2022.9.2)\n",
            "Requirement already satisfied: distributed in /usr/local/lib/python3.8/site-packages (from smac) (2022.9.2)\n",
            "Requirement already satisfied: pynisher>=1.0.0 in /usr/local/lib/python3.8/site-packages (from smac) (1.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/site-packages (from smac) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.8/site-packages (from smac) (1.1.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/site-packages (from smac) (5.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from ConfigSpace>=0.6.0->smac) (4.3.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/site-packages (from ConfigSpace>=0.6.0->smac) (0.29.32)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/site-packages (from ConfigSpace>=0.6.0->smac) (3.0.9)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.8/site-packages (from dask->smac) (2022.8.2)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/site-packages (from dask->smac) (0.11.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from dask->smac) (21.3)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/site-packages (from dask->smac) (2.2.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/site-packages (from dask->smac) (1.3.0)\n",
            "Requirement already satisfied: tornado<6.2,>=6.0.3 in /usr/local/lib/python3.8/site-packages (from distributed->smac) (6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/site-packages (from distributed->smac) (3.0.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/site-packages (from distributed->smac) (1.25.8)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/site-packages (from distributed->smac) (2.4.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.8/site-packages (from distributed->smac) (8.1.3)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/site-packages (from distributed->smac) (1.0.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/site-packages (from distributed->smac) (1.7.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/site-packages (from distributed->smac) (2.2.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/site-packages (from distributed->smac) (1.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn>=0.22.0->smac) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/site-packages (from jinja2->distributed->smac) (2.1.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/site-packages (from zict>=0.1.3->distributed->smac) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimal Example\n",
        "\n",
        "The example optimizes a support vector machine on the iris dataset."
      ],
      "metadata": {
        "id": "ILsSaRp3NJai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ConfigSpace import Configuration, ConfigurationSpace\n",
        "\n",
        "import numpy as np\n",
        "from smac import Scenario\n",
        "from smac import HyperparameterOptimizationFacade as HPOFacade\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "\n",
        "def train(config: Configuration, seed: int = 0) -> float:\n",
        "    classifier = SVC(C=config[\"C\"], random_state=seed)\n",
        "    scores = cross_val_score(classifier, iris.data, iris.target, cv=5)\n",
        "    return 1 - np.mean(scores)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    configspace = ConfigurationSpace({\"C\": (0.1, 1000.0)})\n",
        "\n",
        "    # Scenario object specifying the optimization environment\n",
        "    scenario = Scenario(\n",
        "        configspace,\n",
        "        deterministic=True,  # Use only one seed\n",
        "        n_trials=200,  # We try 200 different C values\n",
        "    )\n",
        "\n",
        "    # Use SMAC to find the best configuration/hyperparameters\n",
        "    smac = HPOFacade(scenario, train, overwrite=True)\n",
        "    incumbent = smac.optimize()"
      ],
      "metadata": {
        "id": "MwmKCXMSNM_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315d2d3f-a534-4b4a-d8b5-f37bbe7d07aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO][abstract_initial_design.py:133] Using 10 initial design and 0 additional configurations.\n",
            "[INFO][intensifier.py:275] No incumbent provided in the first run. Sampling a new challenger...\n",
            "[INFO][intensifier.py:446] First run and no incumbent provided. Challenger is assumed to be the incumbent.\n",
            "[INFO][intensifier.py:566] Updated estimated cost of incumbent on 1 trials: 0.04\n",
            "[INFO][abstract_intensifier.py:340] Challenger (0.0333) is better than incumbent (0.04) on 1 trials.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- C: 266.95183321777733 -> 716.1157102249563\n",
            "[INFO][abstract_intensifier.py:340] Challenger (0.0267) is better than incumbent (0.0333) on 1 trials.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- C: 716.1157102249563 -> 98.85349361812695\n",
            "[INFO][abstract_intensifier.py:340] Challenger (0.0133) is better than incumbent (0.0267) on 1 trials.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- C: 98.85349361812695 -> 5.349895129093992\n",
            "[INFO][base_smbo.py:260] Configuration budget is exhausted.\n",
            "[INFO][abstract_facade.py:325] Final Incumbent: {'C': 5.349895129093992}\n",
            "[INFO][abstract_facade.py:326] Estimated cost: 0.013333333333333308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Fidelity Optimization\n",
        "\n",
        "An example for optimizing a Multi-Layer Perceptron (MLP) using multiple budgets/fidelities. Since we want to take advantage of Multi-Fidelity, the ``MultiFidelityFacade`` is a good choice. By default,\n",
        "``MultiFidelityFacade`` internally runs with [Hyperband](https://arxiv.org/abs/1603.06560) as intensification, which is a combination of an aggressive racing mechanism and successive halving. Crucially, the target function function\n",
        "must accept a budget variable, detailing how much fidelity smac wants to allocate to this configuration.\n",
        "\n",
        "MLP is a deep neural network, and therefore, we choose epochs as fidelity type. This implies that ``budget`` specifies the number of epochs smac wants to allocate. The digits dataset is chosen to optimize the average accuracy on 5-fold cross validation."
      ],
      "metadata": {
        "id": "WEyiSHC0PL_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "from ConfigSpace import (\n",
        "    Categorical,\n",
        "    Configuration,\n",
        "    ConfigurationSpace,\n",
        "    EqualsCondition,\n",
        "    Float,\n",
        "    InCondition,\n",
        "    Integer,\n",
        ")\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from smac import MultiFidelityFacade, Scenario\n",
        "\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "\n",
        "class MLP:\n",
        "    @property\n",
        "    def configspace(self) -> ConfigurationSpace:\n",
        "        # Build Configuration Space which defines all parameters and their ranges.\n",
        "        # To illustrate different parameter types, we use continuous, integer and categorical parameters.\n",
        "        cs = ConfigurationSpace()\n",
        "\n",
        "        n_layer = Integer(\"n_layer\", (1, 5), default=1)\n",
        "        n_neurons = Integer(\"n_neurons\", (8, 256), log=True, default=10)\n",
        "        activation = Categorical(\"activation\", [\"logistic\", \"tanh\", \"relu\"], default=\"tanh\")\n",
        "        solver = Categorical(\"solver\", [\"lbfgs\", \"sgd\", \"adam\"], default=\"adam\")\n",
        "        batch_size = Integer(\"batch_size\", (30, 300), default=200)\n",
        "        learning_rate = Categorical(\"learning_rate\", [\"constant\", \"invscaling\", \"adaptive\"], default=\"constant\")\n",
        "        learning_rate_init = Float(\"learning_rate_init\", (0.0001, 1.0), default=0.001, log=True)\n",
        "\n",
        "        # Add all hyperparameters at once:\n",
        "        cs.add_hyperparameters([n_layer, n_neurons, activation, solver, batch_size, learning_rate, learning_rate_init])\n",
        "\n",
        "        # Adding conditions to restrict the hyperparameter space...\n",
        "        use_lr = EqualsCondition(child=learning_rate, parent=solver, value=\"sgd\")\n",
        "        use_lr_init = InCondition(child=learning_rate_init, parent=solver, values=[\"sgd\", \"adam\"])\n",
        "        use_batch_size = InCondition(child=batch_size, parent=solver, values=[\"sgd\", \"adam\"])\n",
        "\n",
        "        # We can also add multiple conditions on hyperparameters at once:\n",
        "        cs.add_conditions([use_lr, use_batch_size, use_lr_init])\n",
        "\n",
        "        return cs\n",
        "\n",
        "    def train(self, config: Configuration, seed: int = 0, budget: int = 25) -> float:\n",
        "        # For deactivated parameters (by virtue of the conditions),\n",
        "        # the configuration stores None-values.\n",
        "        # This is not accepted by the MLP, so we replace them with placeholder values.\n",
        "        lr = config[\"learning_rate\"] if config[\"learning_rate\"] else \"constant\"\n",
        "        lr_init = config[\"learning_rate_init\"] if config[\"learning_rate_init\"] else 0.001\n",
        "        batch_size = config[\"batch_size\"] if config[\"batch_size\"] else 200\n",
        "\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "            classifier = MLPClassifier(\n",
        "                hidden_layer_sizes=[config[\"n_neurons\"]] * config[\"n_layer\"],\n",
        "                solver=config[\"solver\"],\n",
        "                batch_size=batch_size,\n",
        "                activation=config[\"activation\"],\n",
        "                learning_rate=lr,\n",
        "                learning_rate_init=lr_init,\n",
        "                max_iter=int(np.ceil(budget)),\n",
        "                random_state=seed,\n",
        "            )\n",
        "\n",
        "            # Returns the 5-fold cross validation accuracy\n",
        "            cv = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)  # to make CV splits consistent\n",
        "            score = cross_val_score(classifier, digits.data, digits.target, cv=cv, error_score=\"raise\")\n",
        "\n",
        "        return 1 - np.mean(score)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mlp = MLP()\n",
        "\n",
        "    # Define our environment variables\n",
        "    scenario = Scenario(\n",
        "        mlp.configspace,\n",
        "        walltime_limit=60,  # After 60 seconds, we stop the hyperparameter optimization\n",
        "        n_trials=200,  # Evaluate max 200 different trials\n",
        "        min_budget=5,  # Train the MLP using a hyperparameter configuration for at least 5 epochs\n",
        "        max_budget=25,  # Train the MLP using a hyperparameter configuration for at most 25 epochs\n",
        "        n_workers=1,  # You can use multiple workers for multi-fidelity\n",
        "    )\n",
        "\n",
        "    # We want to run five random configurations before starting the optimization.\n",
        "    initial_design = MultiFidelityFacade.get_initial_design(scenario, n_configs=5)\n",
        "\n",
        "    # Create our SMAC object and pass the scenario and the train method\n",
        "    smac = MultiFidelityFacade(\n",
        "        scenario,\n",
        "        mlp.train,\n",
        "        initial_design=initial_design,\n",
        "        overwrite=True,\n",
        "    )\n",
        "\n",
        "    # Let's optimize\n",
        "    incumbent = smac.optimize()\n",
        "\n",
        "    # Get cost of default configuration\n",
        "    default_cost = smac.validate(mlp.configspace.get_default_configuration())\n",
        "    print(f\"Default cost: {default_cost}\")\n",
        "\n",
        "    # Let's calculate the cost of the incumbent\n",
        "    incumbent_cost = smac.validate(incumbent)\n",
        "    print(f\"Incumbent cost: {incumbent_cost}\")\n"
      ],
      "metadata": {
        "id": "7mT8xCVcPOXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220d28d2-c9c0-471e-e7f7-159d9550fe38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO][abstract_initial_design.py:68] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
            "[WARNING][successive_halving.py:123] The target function is specified to be non-deterministic, but number of seeds to evaluate are set to 1. Consider increasing `n_seeds` from the intensifier.\n",
            "[INFO][successive_halving.py:197] Using successive halving with budget type BUDGETS, min budget 5, max budget 25 and eta 3.\n",
            "[INFO][abstract_initial_design.py:133] Using 5 initial design and 0 additional configurations.\n",
            "[WARNING][abstract_parallel_intensifier.py:93] Hyperband is executed with 1 worker(s) only. However, your system supports up to 2 workers. Consider increasing the workers in the scenario.\n",
            "[INFO][hyperband_worker.py:165] Finished Hyperband iteration-step 1-1 with initial budget 8.\n",
            "[INFO][successive_halving_worker.py:396] First run and no incumbent provided. Challenger is assumed to be the incumbent.\n",
            "[INFO][successive_halving_worker.py:613] Challenger (0.0495) is better than incumbent (0.0568) on budget 8.3333.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- batch_size: None -> 155\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate_init: None -> 0.006677306766018313\n",
            "[INFO][abstract_intensifier.py:367] --- n_layer: 4 -> 5\n",
            "[INFO][abstract_intensifier.py:367] --- n_neurons: 123 -> 56\n",
            "[INFO][abstract_intensifier.py:367] --- solver: 'lbfgs' -> 'adam'\n",
            "[INFO][successive_halving_worker.py:245] Finished Successive Halving iteration-step 1-1 with budget [8.33 / 25] and 3 evaluated challenger(s).\n",
            "[INFO][successive_halving_worker.py:245] Finished Successive Halving iteration-step 1-2 with budget [25.00 / 25] and 1 evaluated challenger(s).\n",
            "[INFO][hyperband_worker.py:165] Finished Hyperband iteration-step 1-2 with initial budget 25.\n",
            "[INFO][successive_halving_worker.py:245] Finished Successive Halving iteration-step 1-1 with budget [25.00 / 25] and 2 evaluated challenger(s).\n",
            "[INFO][hyperband_worker.py:165] Finished Hyperband iteration-step 2-1 with initial budget 8.\n",
            "[INFO][base_smbo.py:260] Configuration budget is exhausted.\n",
            "[INFO][abstract_facade.py:325] Final Incumbent: {'activation': 'tanh', 'n_layer': 5, 'n_neurons': 56, 'solver': 'adam', 'batch_size': 155, 'learning_rate_init': 0.006677306766018313}\n",
            "[INFO][abstract_facade.py:326] Estimated cost: 0.0384060662333644\n",
            "Default cost: 0.4307319715258433\n",
            "Incumbent cost: 0.05008820798514402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Objective Optimization using ParEGO\n",
        "\n",
        "An example of how to use multi-objective optimization with ParEGO. Both accuracy and run-time are going to be optimized, and the configurations are shown in a plot, highlighting the best ones in a Pareto front. The red cross indicates the best configuration selected by SMAC.\n",
        "\n",
        "In the optimization, SMAC evaluates the configurations on three different seeds. Therefore, the plot shows the mean accuracy and run-time of each configuration."
      ],
      "metadata": {
        "id": "I-iKJ48BOVMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ConfigSpace import (\n",
        "    Categorical,\n",
        "    Configuration,\n",
        "    ConfigurationSpace,\n",
        "    EqualsCondition,\n",
        "    Float,\n",
        "    InCondition,\n",
        "    Integer,\n",
        ")\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from smac import HyperparameterOptimizationFacade as HPOFacade\n",
        "from smac import Scenario\n",
        "from smac.facade.abstract_facade import AbstractFacade\n",
        "from smac.multi_objective.parego import ParEGO\n",
        "\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "\n",
        "class MLP:\n",
        "    @property\n",
        "    def configspace(self) -> ConfigurationSpace:\n",
        "        cs = ConfigurationSpace()\n",
        "\n",
        "        n_layer = Integer(\"n_layer\", (1, 5), default=1)\n",
        "        n_neurons = Integer(\"n_neurons\", (8, 256), log=True, default=10)\n",
        "        activation = Categorical(\"activation\", [\"logistic\", \"tanh\", \"relu\"], default=\"tanh\")\n",
        "        solver = Categorical(\"solver\", [\"lbfgs\", \"sgd\", \"adam\"], default=\"adam\")\n",
        "        batch_size = Integer(\"batch_size\", (30, 300), default=200)\n",
        "        learning_rate = Categorical(\"learning_rate\", [\"constant\", \"invscaling\", \"adaptive\"], default=\"constant\")\n",
        "        learning_rate_init = Float(\"learning_rate_init\", (0.0001, 1.0), default=0.001, log=True)\n",
        "\n",
        "        cs.add_hyperparameters([n_layer, n_neurons, activation, solver, batch_size, learning_rate, learning_rate_init])\n",
        "\n",
        "        use_lr = EqualsCondition(child=learning_rate, parent=solver, value=\"sgd\")\n",
        "        use_lr_init = InCondition(child=learning_rate_init, parent=solver, values=[\"sgd\", \"adam\"])\n",
        "        use_batch_size = InCondition(child=batch_size, parent=solver, values=[\"sgd\", \"adam\"])\n",
        "\n",
        "        # We can also add multiple conditions on hyperparameters at once:\n",
        "        cs.add_conditions([use_lr, use_batch_size, use_lr_init])\n",
        "\n",
        "        return cs\n",
        "\n",
        "    def train(self, config: Configuration, seed: int = 0, budget: int = 10) -> dict[str, float]:\n",
        "        lr = config[\"learning_rate\"] if config[\"learning_rate\"] else \"constant\"\n",
        "        lr_init = config[\"learning_rate_init\"] if config[\"learning_rate_init\"] else 0.001\n",
        "        batch_size = config[\"batch_size\"] if config[\"batch_size\"] else 200\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "            classifier = MLPClassifier(\n",
        "                hidden_layer_sizes=[config[\"n_neurons\"]] * config[\"n_layer\"],\n",
        "                solver=config[\"solver\"],\n",
        "                batch_size=batch_size,\n",
        "                activation=config[\"activation\"],\n",
        "                learning_rate=lr,\n",
        "                learning_rate_init=lr_init,\n",
        "                max_iter=int(np.ceil(budget)),\n",
        "                random_state=seed,\n",
        "            )\n",
        "\n",
        "            # Returns the 5-fold cross validation accuracy\n",
        "            cv = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)  # to make CV splits consistent\n",
        "            score = cross_val_score(classifier, digits.data, digits.target, cv=cv, error_score=\"raise\")\n",
        "\n",
        "        return {\n",
        "            \"1 - accuracy\": 1 - np.mean(score),\n",
        "            \"time\": time.time() - start_time,\n",
        "        }\n",
        "\n",
        "\n",
        "def plot_pareto(smac: AbstractFacade) -> None:\n",
        "    \"\"\"Plots configurations from SMAC and highlights the best configurations in a Pareto front.\"\"\"\n",
        "    # Get Pareto costs\n",
        "    _, c = smac.runhistory.get_pareto_front()\n",
        "    pareto_costs = np.array(c)\n",
        "\n",
        "    # Sort them a bit\n",
        "    pareto_costs = pareto_costs[pareto_costs[:, 0].argsort()]\n",
        "\n",
        "    # Get all other costs from runhistory\n",
        "    average_costs = []\n",
        "    for config in smac.runhistory.get_configs():\n",
        "        # Since we use multiple seeds, we have to average them to get only one cost value pair for each configuration\n",
        "        average_cost = smac.runhistory.average_cost(config)\n",
        "\n",
        "        if average_cost not in c:\n",
        "            average_costs += [average_cost]\n",
        "\n",
        "    # Let's work with a numpy array\n",
        "    costs = np.vstack(average_costs)\n",
        "    costs_x, costs_y = costs[:, 0], costs[:, 1]\n",
        "\n",
        "    pareto_costs_x, pareto_costs_y = pareto_costs[:, 0], pareto_costs[:, 1]\n",
        "\n",
        "    plt.scatter(costs_x, costs_y, marker=\"x\")\n",
        "    plt.scatter(pareto_costs_x, pareto_costs_y, marker=\"x\", c=\"r\")\n",
        "    plt.step(\n",
        "        [pareto_costs_x[0]] + pareto_costs_x.tolist() + [np.max(costs_x)],  # We add bounds\n",
        "        [np.max(costs_y)] + pareto_costs_y.tolist() + [np.min(pareto_costs_y)],  # We add bounds\n",
        "        where=\"post\",\n",
        "        linestyle=\":\",\n",
        "    )\n",
        "\n",
        "    plt.title(\"Pareto-Front\")\n",
        "    plt.xlabel(smac.scenario.objectives[0])\n",
        "    plt.ylabel(smac.scenario.objectives[1])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mlp = MLP()\n",
        "\n",
        "    # Define our environment variables\n",
        "    scenario = Scenario(\n",
        "        mlp.configspace,\n",
        "        objectives=[\"1 - accuracy\", \"time\"],\n",
        "        walltime_limit=60,  # After 60 seconds, we stop the hyperparameter optimization\n",
        "        n_trials=200,  # Evaluate max 200 different trials\n",
        "        n_workers=1,\n",
        "    )\n",
        "\n",
        "    # We want to run five random configurations before starting the optimization.\n",
        "    initial_design = HPOFacade.get_initial_design(scenario, n_configs=5)\n",
        "    multi_objective_algorithm = ParEGO(scenario)\n",
        "\n",
        "    # Create our SMAC object and pass the scenario and the train method\n",
        "    smac = HPOFacade(\n",
        "        scenario,\n",
        "        mlp.train,\n",
        "        initial_design=initial_design,\n",
        "        multi_objective_algorithm=multi_objective_algorithm,\n",
        "        overwrite=True,\n",
        "    )\n",
        "\n",
        "    # Let's optimize\n",
        "    # Keep in mind: The incumbent is ambiguous here because of ParEGO\n",
        "    smac.optimize()\n",
        "\n",
        "    # Get cost of default configuration\n",
        "    default_cost = smac.validate(mlp.configspace.get_default_configuration())\n",
        "    print(f\"Default costs: {default_cost}\\n\")\n",
        "\n",
        "    print(\"Validated costs from the Pareto front:\")\n",
        "    for i, config in enumerate(smac.runhistory.get_pareto_front()[0]):\n",
        "        cost = smac.validate(config)\n",
        "        print(cost)\n",
        "\n",
        "    # Let's plot a pareto front\n",
        "    plot_pareto(smac)\n"
      ],
      "metadata": {
        "id": "2YjyyfYCOc77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3fd6b38-1b0a-4c1d-8195-c010c5811b4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO][abstract_initial_design.py:68] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
            "[WARNING][target_function_runner.py:71] The argument budget is not set by SMAC. Consider removing it.\n",
            "[INFO][abstract_initial_design.py:133] Using 5 initial design and 0 additional configurations.\n",
            "[INFO][intensifier.py:275] No incumbent provided in the first run. Sampling a new challenger...\n",
            "[INFO][intensifier.py:446] First run and no incumbent provided. Challenger is assumed to be the incumbent.\n",
            "[INFO][intensifier.py:566] Updated estimated cost of incumbent on 1 trials: 0.5752\n",
            "[INFO][intensifier.py:566] Updated estimated cost of incumbent on 2 trials: 0.2876\n",
            "[INFO][abstract_intensifier.py:340] Challenger (0.4841) is better than incumbent (0.5464) on 2 trials.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- activation: 'logistic' -> 'tanh'\n",
            "[INFO][abstract_intensifier.py:367] --- batch_size: None -> 77\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate_init: None -> 0.000534923804864797\n",
            "[INFO][abstract_intensifier.py:367] --- n_layer: 4 -> 1\n",
            "[INFO][abstract_intensifier.py:367] --- n_neurons: 11 -> 146\n",
            "[INFO][abstract_intensifier.py:367] --- solver: 'lbfgs' -> 'adam'\n",
            "[INFO][abstract_intensifier.py:340] Challenger (0.36) is better than incumbent (0.4872) on 2 trials.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- batch_size: 77 -> 200\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate_init: 0.000534923804864797 -> 0.001\n",
            "[INFO][abstract_intensifier.py:367] --- n_neurons: 146 -> 10\n",
            "[INFO][intensifier.py:566] Updated estimated cost of incumbent on 3 trials: 0.3888\n",
            "[INFO][abstract_intensifier.py:340] Challenger (0.2295) is better than incumbent (0.2438) on 3 trials.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- activation: 'tanh' -> 'relu'\n",
            "[INFO][abstract_intensifier.py:367] --- batch_size: 200 -> 82\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate: None -> 'invscaling'\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate_init: 0.001 -> 0.0001410536676910495\n",
            "[INFO][abstract_intensifier.py:367] --- n_neurons: 10 -> 232\n",
            "[INFO][abstract_intensifier.py:367] --- solver: 'adam' -> 'sgd'\n",
            "[INFO][abstract_intensifier.py:340] Challenger (0.0666) is better than incumbent (0.2312) on 3 trials.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- batch_size: 82 -> 90\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate_init: 0.0001410536676910495 -> 0.0022272721705310374\n",
            "[INFO][abstract_intensifier.py:367] --- n_neurons: 232 -> 178\n",
            "[INFO][abstract_intensifier.py:367] --- solver: 'sgd' -> 'adam'\n",
            "[INFO][abstract_intensifier.py:340] Challenger (0.058) is better than incumbent (0.0666) on 3 trials.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- batch_size: 90 -> 82\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate: None -> 'adaptive'\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate_init: 0.0022272721705310374 -> 0.00028716626681926487\n",
            "[INFO][abstract_intensifier.py:367] --- n_neurons: 178 -> 148\n",
            "[INFO][abstract_intensifier.py:367] --- solver: 'adam' -> 'sgd'\n",
            "[INFO][abstract_intensifier.py:340] Challenger (0.0374) is better than incumbent (0.0464) on 3 trials.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- batch_size: 82 -> 120\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate_init: 0.00028716626681926487 -> 0.000595035491608277\n",
            "[INFO][abstract_intensifier.py:367] --- n_neurons: 148 -> 201\n",
            "[INFO][abstract_intensifier.py:367] --- solver: 'sgd' -> 'adam'\n",
            "[INFO][abstract_intensifier.py:340] Challenger (0.0203) is better than incumbent (0.0789) on 3 trials.\n",
            "[INFO][abstract_intensifier.py:364] Changes in incumbent:\n",
            "[INFO][abstract_intensifier.py:367] --- batch_size: 120 -> 202\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate: None -> 'adaptive'\n",
            "[INFO][abstract_intensifier.py:367] --- learning_rate_init: 0.000595035491608277 -> 0.0008674638976499477\n",
            "[INFO][abstract_intensifier.py:367] --- n_neurons: 201 -> 42\n",
            "[INFO][abstract_intensifier.py:367] --- solver: 'adam' -> 'sgd'\n",
            "[INFO][base_smbo.py:260] Configuration budget is exhausted.\n",
            "[INFO][abstract_facade.py:325] Final Incumbent: {'activation': 'relu', 'n_layer': 1, 'n_neurons': 42, 'solver': 'sgd', 'batch_size': 202, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0008674638976499477}\n",
            "[INFO][abstract_facade.py:326] Estimated cost: 0.03011399508413955\n",
            "Default costs: [0.62956618 0.23099581]\n",
            "\n",
            "Validated costs from the Pareto front:\n",
            "[0.62956618 0.22570737]\n",
            "[0.02912669 1.16946491]\n",
            "[0.09479573 1.01691341]\n",
            "[0.05305478 1.07047645]\n",
            "[0.02022129 6.62456179]\n",
            "[0.138746   0.43309093]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}